# -*- coding: utf-8 -*-
"""IBM_HR_Attrition.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nRty-3GpFwkehN_-3nvyaAkhjssvMjtA
"""

pip install catboost

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from catboost import CatBoostClassifier, Pool
from collections import Counter
from sklearn.model_selection import GridSearchCV
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
from xgboost import XGBClassifier
from sklearn.utils.class_weight import compute_class_weight

data = pd.read_csv("HR-Employee-Attrition.csv")
data.head()

"""#EDA"""

def numeric_summary(df):
  obs = df.shape[0]
  dups = df.duplicated().sum()

  df_numeric = df.select_dtypes(include='number')
  summary_df = pd.DataFrame({
      'Dtype': df_numeric.dtypes,
      'Counts': df_numeric.count(),
      'Nulls': df_numeric.isnull().sum(),
      'Mean': df_numeric.mean(),
      'Median': df_numeric.median(),
      'Min': df_numeric.min(),
      'Max': df_numeric.max(),
      'Uniques': df_numeric.apply(lambda x: x.unique().shape[0]),
      'Unique list': df_numeric.apply(lambda x: list(x.unique()) if x.nunique() < 10 else '-')
  })

  print(obs), print(dups)

  return summary_df

numeric_summary(data)

def object_summary(df):
  obs = df.shape[0]
  dups = df.duplicated().sum()

  df_object = df.select_dtypes(include='object')
  summary_df = pd.DataFrame({
      'Dtype': df_object.dtypes,
      'Counts': df_object.count(),
      'Nulls': df_object.isnull().sum(),
      'Mode': df_object.apply(lambda x: x.mode()[0] if not x.mode().empty else '-'),
      'Frequency': df_object.apply(lambda x: x.value_counts().max() if not x.value_counts().empty else '-'),
      'Uniques': df_object.apply(lambda x: x.unique().shape[0]),
      'Unique list': df_object.apply(lambda x: list(x.unique()) if x.nunique() < 10 else '-')
  })

  print(obs), print(dups)

  return summary_df

object_summary(data)

"""###Dropping a few columns because these feature have only one unique value and does not provide any discriminatory information. It should be removed from the dataset to prevent redundancy."""

data.drop(['EmployeeCount','EmployeeNumber','StandardHours','Over18'], axis=1, inplace=True)

df = data.copy()

cat_data = data.select_dtypes(include='object')
cat_data.drop('Attrition', axis=1, inplace=True)
palette = sns.color_palette('Set2', n_colors=9)

# Loop through each categorical column
for col in cat_data.columns:
    plt.figure(figsize=(10, 5))

    # Group by the column and Attrition, count the occurrences
    grouped_data = data.groupby([col, 'Attrition']).size().reset_index(name='Count')

    # Plot the bar plot
    sns.barplot(data=grouped_data, x=col, y='Count', hue='Attrition', palette=palette)

    # Customize the plot
    plt.title(f'Bar Plot of {col} with Attrition')
    plt.xlabel(col)
    plt.ylabel('Count')
    plt.xticks(rotation=45)  # Rotate x-axis labels if needed
    plt.tight_layout()
    plt.show()

num_data = data.select_dtypes(include='number')
corr = num_data.corr()
plt.figure(figsize=(20,10))
sns.heatmap(corr, annot=True)

sns.set(style="whitegrid")

plt.figure(figsize=(8, 6))

sns.boxplot(x='JobLevel', y='MonthlyIncome', data=data, palette='Set3')

plt.title('Monthly Income Distribution by Job Level', fontsize=14)
plt.xlabel('Job Level', fontsize=12)
plt.ylabel('Monthly Income', fontsize=12)

plt.show()

data.drop(['JobLevel'], axis=1, inplace=True)

"""###There is class imbalanace so we have to deal with it using SMOTE"""

data['Attrition'].value_counts()

data['Attrition'].value_counts().plot.pie(autopct='%.2f')

"""#Data Preprocessing

##Encoding categorical variables
###Label Encoding   
Attrition --> No:0 Yes:1   
Gender --> Female:0 Male:1  
OverTime --> No:0 Yes:1
"""

le = LabelEncoder()
data['Attrition'] = le.fit_transform(data['Attrition'])
data['Gender'] = le.fit_transform(data['Gender'])
data['OverTime'] = le.fit_transform(data['OverTime'])

"""###One Hot Encoding"""

encoder = OneHotEncoder(sparse_output=False, drop='first', dtype=int)
features = ['BusinessTravel', 'Department', 'EducationField', 'JobRole', 'MaritalStatus']

for i in features:
  encoded_array = encoder.fit_transform(data[[i]])
  encoded_df = pd.DataFrame(encoded_array, columns=encoder.get_feature_names_out([i]))
  data = pd.concat([data, encoded_df], axis=1)
  data.drop(i, axis=1, inplace=True)

data

"""###Applying SMOTE (Synthetic Minority Over-sampling Technique) for class imbalance"""

X = data.drop('Attrition', axis=1)
y = data['Attrition']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=29)

temp = y_test

smote = SMOTE(random_state=29)
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)

"""#Logistic Regression"""

lasso_logreg = LogisticRegression(
    penalty='l1',          # Using L1 regularization (Lasso)
    solver='liblinear',
    C=1,
    max_iter=1000,
    random_state=42
)

lasso_logreg.fit(X_train_smote, y_train_smote)

y_pred_logreg = lasso_logreg.predict(X_test)
y_pred_proba_logreg = lasso_logreg.predict_proba(X_test)[:, 1]

print("\nClassification Report")
print(classification_report(y_test, y_pred_logreg))

cm = confusion_matrix(y_test, y_pred_logreg)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

auc_score = roc_auc_score(y_test, y_pred_proba_logreg)
print("AUC Score:", auc_score)

"""#Random Forest Classifier"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import RandomizedSearchCV
from sklearn.metrics import classification_report

param_dist = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

rf = RandomForestClassifier(random_state=29)

random_search = RandomizedSearchCV(
    estimator=rf,
    param_distributions=param_dist,
    n_iter=20,  # Test 20 random combinations
    cv=5,       # 5-fold cross-validation
    scoring='roc_auc',
    verbose=1,
    n_jobs=-1,
    random_state=29
)

random_search.fit(X_train_smote, y_train_smote)

print("Best Parameters for Random Forest:", random_search.best_params_)

rf = random_search.best_estimator_

y_pred_rf = rf.predict(X_test)
y_pred_proba_rf = rf.predict_proba(X_test)[:, 1]

print("\nClassification Report")
print(classification_report(y_test, y_pred_rf))

cm = confusion_matrix(y_test, y_pred_rf)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

auc_score = roc_auc_score(y_test, y_pred_proba_rf)
print("AUC Score:", auc_score)

"""#Gradient Boosting

###XGBoost
"""

xgb = XGBClassifier(
    objective='binary:logistic',
    eval_metric='logloss',
    use_label_encoder=False,
    random_state=29
)

xgb.fit(X_train_smote, y_train_smote)

y_pred_xgb = xgb.predict(X_test)
y_pred_proba_xgb = xgb.predict_proba(X_test)[:,1]

print("\nClassification Report")
print(classification_report(y_test, y_pred_xgb))

cm = confusion_matrix(y_test, y_pred_xgb)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

auc_score = roc_auc_score(y_test, y_pred_proba_rf)
print("AUC Score:", auc_score)

#Feature Importance

importances = xgb.feature_importances_
feature_names = X_train_smote.columns

importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})
importance_df = importance_df.sort_values(by='Importance', ascending=False)

plt.figure(figsize=(10, 8))
plt.barh(importance_df['Feature'], importance_df['Importance'])
plt.title('Feature Importance (XGBoost)')
plt.xlabel('Importance')
plt.ylabel('Features')
plt.gca().invert_yaxis()
plt.show()

"""###CatBoost"""

data = df

X = data.drop('Attrition', axis=1)
y = data['Attrition']

categorical_features = [X.columns.get_loc(col) for col in X.select_dtypes(include='object').columns]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=29, stratify=y
)

classes = np.array(['Yes', 'No'])

class_weights = compute_class_weight(
    class_weight='balanced',
    classes=classes,
    y=y_train
)

class_weights_dict = dict(zip(classes, class_weights))

y_train_numeric = y_train.map({'Yes': 1, 'No': 0})

catboost = CatBoostClassifier(
    iterations=100,
    learning_rate=0.1,
    depth=6,
    eval_metric='AUC',
    class_weights=[class_weights_dict['No'], class_weights_dict['Yes']],  # Ensure order matches numeric mapping
    cat_features=categorical_features,
    random_seed=42,
    verbose=50
)

catboost.fit(X_train, y_train, eval_set=(X_test, y_test), early_stopping_rounds=20)

y_pred_catboost = catboost.predict(X_test)
y_pred_proba_catboost = catboost.predict_proba(X_test)[:, 1]  # Probabilities for the positive class

print("\nClassification Report:")
print(classification_report(y_test, y_pred_catboost))

cm = confusion_matrix(y_test, y_pred_catboost)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

y_test_numeric = y_test.map({'Yes': 1, 'No': 0})

auc_score = roc_auc_score(y_test_numeric, y_pred_proba_catboost)
print("AUC Score:", auc_score)

#Feature Importance
feature_names = X.columns

feature_importance = catboost.get_feature_importance(type='FeatureImportance')
importance_df = pd.DataFrame({
    'Feature': feature_names,
    'Importance': feature_importance
}).sort_values(by='Importance', ascending=False)

plt.figure(figsize=(10, 8))
plt.barh(importance_df['Feature'], importance_df['Importance'], color='skyblue')
plt.xlabel('Importance')
plt.ylabel('Features')
plt.title('CatBoost Feature Importance')
plt.gca().invert_yaxis()
plt.show()

models = {
    "Logistic Regression": y_pred_proba_logreg,
    "Random Forest": y_pred_proba_rf,
    "XGBoost": y_pred_proba_xgb,
    "CatBoost": y_pred_proba_catboost
}

plt.figure(figsize=(10, 8))

for model_name, y_pred_proba in models.items():
  if model_name == "CatBoost":
    fpr, tpr, _ = roc_curve(y_test_numeric, y_pred_proba)
    auc_score = roc_auc_score(y_test_numeric, y_pred_proba)
    plt.plot(fpr, tpr, label=f"{model_name} (AUC = {auc_score:.2f})")

  else:
    fpr, tpr, _ = roc_curve(temp, y_pred_proba)
    auc_score = roc_auc_score(temp, y_pred_proba)
    plt.plot(fpr, tpr, label=f"{model_name} (AUC = {auc_score:.2f})")

plt.plot([0, 1], [0, 1], 'k--', label="Random Guess")
plt.title("Combined ROC Curve for All Models")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend(loc="lower right")
plt.grid(True, which='both', linestyle='--', linewidth=0.5)
plt.show()

